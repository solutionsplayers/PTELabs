export const summerize_text = [
  {
    id: 1,
    ques: "Many insecurities, fears, and doubts stem from lack of understanding or lack of knowledge about something. The more you understand and know about a situation, the more comfortable you will be and thus the less power your shyness will have over you. Let’s take for example the subject of public speaking. This is an activity that terrifies most people half to death, but only because most people don’t have much knowledge about it. If you do some research and investigation, you’ll come to learn that it’s perfectly natural to be terrified of public speaking, and that almost every single person has the same fears and insecurities that you do. When you take it further and ask yourself why you are so terrified of this, you’ll come to learn that you are scared of being judged, or of being laughed at. From there, you can go and read and learn about people who are good at public speaking—learn their tips and strategies. This way you are much more prepared because your knowledge on the subject is vast. As a result of this, your confidence will already be much higher than before, which might allow you to attempt public speaking when you join a club like Toastmasters. As you practice more, you will naturally become even more confident. This rule applies to any area where you feel insecure. Read and research as much about the topic as possible. This will help increase your confidence enough to give the activity a try to see if you might be able to become better at it. And that initial confidence to take action is all you need to get the ball rolling and overcome your shyness.",
    ans: "",
  },
  {
    id: 2,
    ques: " Most sea creatures, from whales and dolphins to fish, sharks, shrimps and possibly even anemones respond to sound, and many can produce it. They use it to hunt and to hide, find mates and food, form and guide shoals, navigate 'blind', send messages and transmit warnings, establish territories, warn off competitors, stun prey, deceive predators, and sense changes in water and conditions. Marine animals click bones and grind teeth; use drum-tight bladders and special sonic organs to chirp, grunt, and boom: belch gases; and vibrate special organs. Far from the 'silent deep', the oceans are a raucous babel. Into this age-long tumult, in the blink of an evolutionary eye, has entered a new thunder: the throb of mighty engines as 46,220 large vessels plough the world's shipping lanes. Scientists say that background noise in the ocean has increased roughly by 15 decibels in the past 50 years. It may not sound like much in overall terms; but it is enough, according to many marine biologists, to mask the normal sounds of ocean life going about its business. At its most intense, some even say noise causes whales to become disoriented, dolphins to develop 'the bends', fish to go deaf, flee their breeding grounds or fail to form shoals - enough to disrupt the basic biology of two thirds of the planet. 'Undersea noise pollution is like the death of a thousand cuts', says Sylvia Earle, chief scientist of the US National Oceanic and Atmospheric Administration. 'Each sound in itself may not be a matter of critical concern, but taken all together, the noise from shipping, seismic surveys, and military activity is creating a totally different environment than existed even 50 years ago. That high level of noise is bound to have a hard, sweeping impact on life in the sea. ",
    ans: "",
  },
  {
    id: 3,
    ques: " The National Oceanography Center (NOC) is engaged in research into the potential risks and benefits of exploiting deep-sea mineral resources, some of which are essential for low-carbon technology, as well as using ocean robots to estimate the environmental impact of these potential deep-sea mining activities. Late last year the NOC led an expedition on the RRS James Cook that found enough of the scarce element Tellurium present in the crust of a submerged volcano that, if it were all to be used in the production of solar PV panels, could provide two-thirds of the UK's annual electricity supply. Recently, the NOC also led an international study demonstrating deep-sea nodule mining will cause long-lasting damage to deep-sea life, lasting at least for decades. These nodules are potato-sized rocks containing high levels of metals, including copper, manganese and nickel. They grow very slowly on the sea-bed, over millions of years. Although no commercial operations exist to extract these resources, many are planned. Professor Edward Hill, Executive Director at the NOC commented, By 2050 there will be nine billion people on earth and attention is increasingly turning to the ocean, particularly the deep ocean, for food, clean supplies of energy and strategic minerals. The NOC is undertaking research related to many aspects and perspectives involved in exploiting ocean resources. This research is aimed at informing with sound scientific evidence the decisions that will need to be taken in the future, as people increasingly turn to the oceans to address some of society's greatest challenges.",
    ans: "",
  },
  {
    id: 4,
    ques: " Let us begin by asking why the conviction that our language is decaying is so much more widespread than the belief that it is progressing, in an intellectual climate where the notion of the survival of the fittest is at least as strong as the belief in inevitable decay, it is strange that so many people are convinced of the decline in the quality of English, a language which is now spoken by an estimated half billion people – a possible hundredfold increase in the number of speakers during the past millennium. One’s first reaction is to wonder whether the members of the anti-slovenliness brigade, as we may call them, are subconsciously reacting to the fast-moving world we live in, and consequently resenting change in any area of life. To some extent this is likely to be true. A feeling that ‘fings ain’t wot they used to be’ and an attempt to preserve life unchanged seem to be natural reactions to insecurity, symptoms of growing old. Every generation inevitably believes that the clothes, manners and speech of the following one have deteriorated. We would therefore expect to find a respect for conservative language in every century and every culture and, in literate societies, a reverence for the language of the ‘best authors’ of the past. ",
    ans: "",
  },
  {
    id: 5,
    ques: " Broadly speaking, there are two different ways of thinking about modern art, or two different versions of the story. One way is to view art as something that can be practiced (And though of) as an activity radically separate from everyday life or worldly concerns. From this point of view, art is said to be “autonomous” from society – that is, it is believed to be self-sustaining and selfreferring. One particularly influential versions of this story suggest that modern art should be viewed as process by which features extraneous to a particular branch of art would be progressively eliminated, and painters or sculptors would come to concentrate on problems specific to their domain. Another way of thinking about modern art is to view it as responding to the modern world, and to see modern artists immersing themselves in the conflicts and challenges of society. That is to say, some modern artists sought ways of conveying the changing experiences generated in European by the twin processes of commercialization (the commodification of everyday life) and urbanization. From this point of view, modern art is a way of reflecting on the transformation that created what we call, in a sort of shorthand, “modernity”.",
    ans: "",
  },
  {
    id: 6,
    ques: "Skipping Breakfast Has Drawbacks - It's no mystery why so many people routinely skip breakfast: bad timing. It comes at a time when folks can be more occupied with matters of grooming, attire and otherwise making themselves presentable for a new day. However, studies conducted both in the United States and internationally have shown that skipping breakfast can affect learning, memory and physical well-being. Students who skip breakfast are not as efficient at selecting critical information for problem-solving as their peers who have had breakfast. For school children, skipping breakfast diminishes the ability to recall and use newly acquired information, verbal fluency, and control of attention, according to Ernesto Pollitt, a UC Davis professor of pediatrics whose research focuses on the influence of breakfast on mental and physical performance. Skipping breakfast can impair thinking in adults, also. For both children and adults, a simple bowl of cereal with milk goes a long way toward providing a sufficiently nutritious start to the day. Green-Burgeson recommends choosing a cereal that's low in sugar — less than five grams per serving — and using nonfat or one percent milk. Frederick Hirshburg, a pediatrician at UC Davis Medical Group, Carmichael, says that babies and other preschoolers rarely skip breakfast because they're usually the hungriest at the beginning of the day. Breakfast then becomes more of a learned experience than a response to a biological need, Hirshburg says. ",
    ans: "",
  },
  {
    id: 7,
    ques: ` It wasn't until the 19th century that Britain had a police force as we know it today. In medieval times, the maintenance of law and order was in the hands of local nobles and lords who were expected to keep the peace in their own land, and they would often appoint "constables" to police it. For a long time policing remained an unpaid activity or was paid for privately, either by individuals or organizations. There were also people who made a living as "thief takers". They were not paid wages, but were rewarded by a proportion of the value of the stolen possessions they recovered. Later, in London, where the population was rapidly increasing crime was rising, night-watchmen — the first paid law enforcement body — were created and worked alongside the unpaid, part-time constables. Britain, then, was slower to create and develop a police force than the rest of Europe: France had one long before — indeed, the word police is taken from the French. This fact was not unimportant, as the very idea of a police force was seen as foreign — that is, French — and particularly undesirable, and was generally regarded as a form of oppression. It was not until Robert Peel set up his "new police" as a separate force in 1829 that policemen began to replace the old part-time constables. Sir Robert "Bobby" Peel's own name provided two common nicknames for the new force: "Peelers" or "Bobbies". These names seem mild, if not affectionate, and are possibly an interesting gauge of how the police were viewed by people at the time, in contrast with the kind of names they get called these days. `,
    ans: "",
  },
  {
    id: 8,
    ques: ` For those political analysts whose main interest remains class divisions in society the biggest split these days is that between those who control and work with informational technology (IT) and those we might still call blue-collar workers. The old divisions of class have become a lot more difficult to apply, if not completely outdated. There's no escaping the enormous impact of information technology in the late 20th and, even more, the early 21st centuries, both economically and socially. During the scientific revolution of the 17th and 18th centuries, the spirit of experiment was in the air, and those involved were practical people working to practical ends — often on their own or with a small group of trusted friends. Secrecy was important as there was money to be made in new inventions. What interested them were results, not theories. Most modern technological advances, however, were developed as theories first, and then made reality by large teams of scientists and experts in the field. What we have now is that more and more of this type of expertise is being used to analyse and find solutions to all kinds of business and social problems, thus creating — in the eyes of the political analysts mentioned above — a whole large new economic and social class. `,
    ans: "",
  },
  {
    id: 9,
    ques: ` Over the years, language teachers have alternated between favoring teaching approaches that focus primarily on language use and those that focus on language forms or analysis. The alternation has been due to a fundamental disagreement concerning whether one learns to communicate in a second language by communicating in that language (such as in an immersion experience) or whether one learns to communicate in a second language by learning the lexicogrammar – the words and grammatical structures – of the target language. In other words, the argument has been about two different means of achieving the same end. As with any enduring controversy, the matter is not easily resolved. For one thing, there is evidence to support both points of view. It is not uncommon to find learners who, for whatever reason, find themselves in a new country or a new region of their own country, who need to learn a new language, and who do so without the benefit of formal instruction. If they are postpubescent, they may well retain an accent of some kind, but they can pick up enough language to satisfy their communicative needs. In fact, some are natural acquirers who become highly proficient in this manner. In contrast, there are learners whose entire exposure to the new language comes in the form of classroom instruction in lexicogrammar. Yet they too achieve a measure of communicative proficiency, and certain of these learners become highly proficient as well. What we can infer from this is that humans are amazingly versatile learners and that some people have a natural aptitude for acquiring languages and will succeed no matter what the circumstances. `,
    ans: "",
  },
  {
    id: 10,
    ques: `According to researchers, the invisibility cloak illusion stems from the belief that we are much more socially observant than the people around us. This means that, while we watch and wonder about other people as much as possible, we often think that people around us are less aware. This illusion occurs because, while we are fully aware of our own impressions and speculations about other people, we have no idea about what those other people are thinking unless they choose to share with us, something that rarely happens except in exceptional circumstances. To better understand what is happening, it is important to consider the groundbreaking research by Amos Tversky and Daniel Kahneman on cognitive biases. When people make judgments about other people in social situations, they often depend on specific biases such as the availability heuristic, i.e., that we attach more significance to thoughts that come to mind easily. This is why we consider thoughts about other people as being more important than thoughts about inanimate objects. And so, as we look around us, we tend to focus our thoughts on the people we see and what they happen to be doing. Which is why people-watching can be so addictive. What adds to the sense that we are relatively invisible to others is that people tend to be as discreet as possible about their people-watching. Just because other people aren't sharing their observations with us, it's easy to pretend that they are not as observant as we are. Of course, people may share their people-watching observations with anyone they happen to be with but, for the most part, that only applies to something remarkable enough to comment on. For most of us, what we are seeing tends to be extremely private and not to be shared with others. `,
    ans: "",
  },
  {
    id: 11,
    ques: ` As an art, architecture is essentially abstract and nonrepresentational and involves the manipulation of the relationships of spaces, volumes, planes, masses, and voids. Time is also an important factor in architecture, since a building is usually comprehended in a succession of experiences rather than all at once. In most architecture there is no one vantage point from which the whole structure can be understood. The use of light and shadow, as well as surface decoration, can greatly enhance a structure. The analysis of building types provides an insight into past cultures and eras. Behind each of the greater styles lies not a casual trend nor a vogue, but a period of serious and urgent experimentation directed toward answering the needs of a specific way of life. Climate, methods of labor, available materials, and economy of means all impose their dictates. Each of the greater styles has been aided by the discovery of new construction methods. Once developed, a method survives tenaciously, giving way only when social changes or new building techniques have reduced it. That evolutionary process is exemplified by the history of modern architecture, which developed from the first uses of structural iron and steel in the mid-19th cent. `,
    ans: "",
  },
  {
    id: 12,
    ques: ` Humans love to complain to each other. It helps us feel less alone. Think about what happens when a family member or friend is going through a tough time; they call up someone who will listen to their tale of woe. Unfortunately, negative bonding is the default for many groups. In some families complaining is the only way to get attention. When one person says, I had a bad day; the other person has to top it. "You think you had a tough day, I had to do three TPS reports!" The same thing happens at work and social settings. "Your child didn't sleep through the night until 6 months? Mine was a full year old before she went over six hours." It's a race to the bottom, the worst situation wins. In Bitching is Bonding, A Guide To Mutual Complaint, Irene S. Levine, Ph.D., a professor of psychiatry at the NYU Langone School of Medicine says, "the reason these conversations feel good is because we feel understood." People raised in negative environments learn early on, being positive gets you thrown out of the club. When family dinner is a complaint fest, you’re not going to risk alienation saying, "Wow, I had an awesome day, don't you just love life?" Translate this into a work setting, people, often unconsciously, believe being positive keeps you out of the cool club. When negativity provides bonding, humans are reluctant to abandon the behavior that brings them comfort. `,
    ans: "",
  },
  {
    id: 13,
    ques: ` Mammals can be one of the hardest-hit groups by habitat loss, and a lot of research has been carried out to find the best ways to conserve mammal diversity. Much of this research has focussed on very large-scale changes in land use and the impacts this will have on overall mammal diversity. However, many important decisions about land use aremade at much more local scales, for example at the level of individual landowners. Now, in a detailed study led by Imperial College London that looked at mammal diversity across different small-scale landscapes in Borneo, researchers have identified previously logged forests as an overlooked source of refuge for mammals. These ‘selectively logged’ forests, where only certain tree species are removed, are often considered to be degraded and are frequently cleared to make way for plantations. The new results, published in the journal Ecological Applications, suggest they should be better protected. The team recorded mammals using trap-and-release techniques and motion-sensing cameras over three years, creating an unprecedented 20,000 records of species in three land-use types: old-growth forest, logged forest and oil palm plantation. This is one of the most intensive studies of rainforest mammal diversity ever undertaken. To their surprise, they found that mammal diversity for large mammals, like the clouded leopard and civets, was similar for both old-growth forests and logged forests. For small mammals, such as squirrels and rodents, the diversity was actually higher in logged forests. `,
    ans: "",
  },
  {
    id: 14,
    ques: ` The soil dwelling fungus ‘take-all’ inflicts devastating stress to the roots of cereals crops worldwide and is a major disease problem in UK wheat crops. However, recent field trial data from Rothamsted Research, an institute of the BBSRC, has demonstrated that farmers could control this devastating disease by selecting wheat cultivars that reduce take-all build up in the soil when grown as a first wheat. Wheat is an important staple crop worth 1.6 Billion a year to the UK economy alone. This work funded by the Biotechnology and Biological Sciences Research Council (BBSRC), the Department for the Environment, Food and Rural Affairs (Defra) and the HGCA will help farmers to increase yields, combating global food security and contributing to UK economic growth. Take-all disease, caused by the fungus, Gaeumannomyces graminis var. tritici, reduces grain yield and quality and results in an increased amount of residual applied nitrogen fertiliser left in the soil post-harvest. Despite the use of chemical, biological and cultural control methods the take-all fungus is still one of the most difficult pathogens of wheat to control. The risk of take-all infection in second and third wheat crops is directly linked to the amount of fungus remaining in the soil after the first wheat is harvested. The Rothamsted Research study, published in Plant Pathology, has demonstrated that wheat cultivars differ in their ability to build-up the take-all fungus. Growing a low building cultivar, such as Cadenza, as a first wheat crop can be used to manipulate take-all inoculum levels in the soil resulting in better yields from the second and third wheat crops. Yield increases of up to 2 tonnes per hectare in 2nd wheats have been observed. `,
    ans: "",
  },
  {
    id: 15,
    ques: ` Working nine to five for a single employer bears little resemblance to the way a substantial share of the workforce makes a living today. Millions of people assemble various income streams and work independently, rather within last in structured payroll jobs. This is at hardly a new phenomenon, yet it has never been well measured in official statistics-and the resulting data gaps prevent a clear view of a large share of labor-market activity. To better understand the independent workforce and what motivates the people who participate in it, the McKinney global institute surveyed some 8,000 respondents across Europe and the United States. We asked about their income in the past 12 months—encompassing primary work, as well as any other income-generating activities—and about their professional satisfaction and aspirations for work in the future. The resulting report, independent work: choice, necessity, and the gig economy, finds that up to 162 million people in Europe and the United States—or 20 to 30 percent of the working-age population—engage in some form of independent work. while demographically diverse, independent workers largely fit into four segments (exhibit): free agents, who active choose independent work and derive their primary income from it; casual earners, who use independent work for supplemental income and do so by choice; reluctants, who make their primary living from independent work but would prefer traditional jobs; and the financially strapped, who do supplemental independent work out of necessity. `,
    ans: "",
  },
  {
    id: 16,
    ques: ` The saying "The camera never lies." has been with us almost since the beginning of photography — yet we all now know that it can, and does lie, and very convincingly. Yet most of us still seem to trust the truth of a photographic image — especially in our newspapers or on TV news reports — even though we may question its message. We think of photographs as an accurate reflection of unaltered reality. We're convinced of this when we take unposed snaps on our family holidays or of colleagues the worse for wear at the office party. It is this property of photography that makes it hard to question the evidence before our eyes. Our holiday snaps, though, like photographs showing life ten, fifty, a hundred years ago, tend only to bring about at most a feeling of nostalgia — not always a negative emotion. Many people keep albums to relive the better moments of their lives — and their impact is reduced by the fact that what they show is over, part of history. News photos, on the other hand, in presenting moments of an event that is probably still going on somewhere, must provoke a more vivid, emotional response. `,
    ans: "",
  },
  {
    id: 17,
    ques: ` Times are fraught, and overstretched executives are constantly on the lookout for a way to clear their minds so they can work in a calmer, more effective, and more responsive way. Cultivating a special state of consciousness called 'mindfulness' — an intense awareness of the here and now — is proving attractive to a growing number of senior managers, both in the US and elsewhere. Mindfulness is achieved by meditation techniques, often involving sitting on a cushion, eyes closed, concentrating on the inflow and outflow of your breath. Or you might spend 10 minutes studying, sniffing, tasting and finally eating a piece of fruit. That might make it sound like a remnant of the navel-gazing 1960s and 1970s, but the evidence for mindfulness's effectiveness is good enough to have impressed hard-nosed companies such as Google (which has invited mindfulness gurus to speak at the Googleplex), General Mills, PricewaterhouseCoopers, Deutsche Bank, Procter & Gamble, AstraZeneca, Apple, Credit Suisse, KPMG, Innocent, Reuters and many more. According to Don McCormick, assistant professor of management at California State University and a dedicated meditator, it 'can help individuals to manage workplace stress, perform tasks more effectively, enhance self-awareness and self-regulation, experience work as more meaningful, improve workplace relationships, increase ethical behavior, and make perception more accurate'. It is said to pay dividends for leaders and managers, by improving the quality of their listening and communicating. `,
    ans: "",
  },
  {
    id: 18,
    ques: ` The shipping container is one of the mainstays of international trade. The globalized modern economy depends on the rapid and efficient movement of goods that containerization allows. In many ways, it was the advent of the container that allowed this globalized economy to develop. Invented during World War two as an efficient method of moving equipment to the front lines, there are now at any one time up to 15 million containers being used to transport goods on land and sea or waiting to be filled at factories And ports. They are vital in the supply chain and have allowed the added efficiency of "just in time" inventory management, where companies no longer keep large warehouses of stock or parts, but rely on the ability to quickly order what they want From their suppliers. It is estimated that since the 1980s the ratio of inventory to GDP in American business has fallen from 25% to 15%. Altogether total business inventory in the US is estimated at $1.5 trillion, without "just in time" management methods this might be as much as $2.5 trillion. This means that companies rely more and more on the prompt delivery of parts from their suppliers to the fulfill orders. this is as particularly to true of industries such as computer manufacture, which no longer the make all the parts of the products that bear their names, but instead out source, often field to the suppliers halfway around at the world. American computer manufacturers are, for example, increasingly dependent on Asian microchip manufacturers in the countries such as Taiwan and Thailand. `,
    ans: "",
  },
  {
    id: 19,
    ques: ` Tradition and commerce often clash in many cultures. In Trinidad, it is the Carnival that is the cause of current friction. The complaint, as you would expect, is that traditional skills and creativity are being lost in the rush to make profits. And the profits are large: the two-day festival, which attracts up to 40,000 tourists each year, is estimated to generate somewhere between $27 million and $100 million. A particular problem for the traditionalists is that the extravagant colorful costumes people wear in the bands or processions are now largely being imported, especially from China. These costumes are cheaper and more revealing (another cause of complaint) than those made locally. Critics say these imports are a threat to traditional creations and, worse, mean sending work elsewhere. Others see turning the Carnival into a profitable and exportable industry as a progressive move, benefiting the country as a whole.
 A large number of people are in two minds. On the one hand, the changes are a reflection of what people - mainly tourists - want, and bring in money. On the other, there is a desire to preserve traditions. The transformation of the bands and processions into businesses has disrupted the social order, which used to be made up of friends getting together to relax, eat and drink, and make costumes. Both sides agree,though, that the country needs to make better use of the skills of the people in the Carnival business and that the country's resources must appeal to a wider market.
 `,
    ans: "",
  },
  {
    id: 20,
    ques: ` You used to think that being green was a luxury for your company, but climate change has made you realize that you can no longer ignore it. The buzz is about becoming carbon-neutral, but where do you start? Consider your drivers. Do you want to become carbon-neutral for marketing reasons, for financial reasons or to help save the planet? Simon Armitage of the Carbon Neutral Company believes: "Your drivers will help you tailor your carbon-reduction program and determine key performance indicators." This will help build a case for going carbon-neutral. First, measure your carbon footprint, or get a specialist to do it for you. That primarily means taking account of your energy usage and emissions caused through travel. Before you begin, think about whether you're collecting the right data and whether it's readily accessible. When implementing any energy reduction measures, ensure you engage with your staff. "It's much better if your people decide for themselves when it's sensible for them to travel," says Armitage. You'll also need them to participate in switching off the lights and other energy-saving measures. Set targets and show it's not a one-off exercise. `,
    ans: "",
  },
  {
    id: 21,
    ques: ` Brand loyalty exists when consumers repeat-purchase your brand rather than swapping and switching between brands. It is widely agreed that it is far more expensive to have to find a new customer than to keep existing ones happy, so brand loyalty is crucial for achieving high-profit margins. For charities, it is important to set a marketing objective of improving brand loyalty. If existing donors can be persuaded to set up a direct debit to the charity, its cash flow will improve significantly. To enhance, or reposition a brand's image Although some brands stay fresh for generations (Marmite is over 100 years old) others become jaded due to changes in consumer tastes and lifestyles. At this point, the firms need to refresh the brand image to keep the products relevant to the target market. A clear objective must be set. For instance: what brand attributes do we want to create? What do we want the brand to stand for? Repositioning This occurs when a firm aims to a change a brand’s image, so that the brand appeals to a new target market. Twelve years into its life cycle, McVitie's decided to reposition its Hobnobs biscuit brand. Hobnobs had been positioned as a homely, quite healthy biscuit for middle-aged consumers. Research pointed McVitie's in a new direction: younger, more male, and less dull. So new packaging was designed and then launched in conjunction with a new, brighter advertising campaign. In 2013 Hobnobs sales were worth 36 million pounds, 9 percent up on the previous year. `,
    ans: "",
  },
  {
    id: 22,
    ques: ` According to the theory of continental drift, the world was made up of a single continent through most of geologic time. That continent eventually separated and drifted apart, forming into the seven continents we have today. The first comprehensive theory of continental drift was suggested by the German meteorologist Alfred Wegener in 1912. The hypothesis asserts that the continents consist of lighter rocks that rest on heavier crustal material—similar to the manner in which icebergs float on water. Wegener contended that the relative positions of the continents are not rigidly fixed but are slowly moving—at a rate of about one yard per century. According to the generally accepted plate-tectonics theory, scientists believe that Earth's surface is broken into a number of shifting slabs or plates, which average about 50 miles in thickness. These plates move relative to one another above a hotter, deeper, more mobile zone at average rates as great as a few inches per year. Most of the world's active volcanoes are located along or near the boundaries between shifting plates and are called plate-boundary volcanoes. The peripheral areas of the Pacific Ocean Basin, containing the boundaries of several plates, are dotted with many active volcanoes that form the so-called Ring of Fire. The Ring provides excellent examples of plate-boundary volcanoes, including Mount St. Helens. However, some active volcanoes are not associated with plate boundaries, and many of these so-called intra-plate volcanoes form roughly linear chains in the interior of some oceanic plates. The Hawaiian Islands provide perhaps the best example of an intra-plate volcanic chain, developed by the northwest-moving Pacific plate passing over an inferred “hot spot” that initiates the magma-generation and volcano-formation process. `,
    ans: "",
  },
  {
    id: 23,
    ques: ` Research shows that when people work with a positive mind-set, performance on nearly every level – productivity, creativity, engagement - improves. Yet happiness is perhaps the most misunderstood driver of performance. For one, most people believe that success precedes happiness. “Once I get a promotion, I'll be happy,” they think. Or, “Once I hit my sales target, I'll feel great.” But because success is a moving target – as soon as you hit your target, you raise it again, the happiness that results from success is fleeting. In fact, it works the other way around: People who cultivate a positive mind-set perform better in the face of challenge. I call this the "happiness advantage” – every business outcome shows improvement when the brain is positive. I've observed this effect in my role as a researcher and lecturer in 48 countries on the connection between employee happiness and success. And I'm not alone: In a meta-analysis of 225 academic studies, researchers Sonja Lyubomirsky, Laura King, and Ed Diener found strong evidence of directional causality between life satisfaction and successful business outcomes. Another common misconception is that our genetics, our environment, or a combination of the two determines how happy we are. To be sure, both factors have an impact. But one's general sense of well-being is surprisingly malleable. The habits you cultivate, the way you interact with coworkers, how you think about stress – all these can be managed to increase your happiness and your chances of success. `,
    ans: "",
  },
  {
    id: 24,
    ques: ` A country's standard of living generally depends on the size of its national income. Standards of living are measured by such things as the number of cars, televisions, telephones, computers, washing machines, and so on, for every one thousand people. There is, however, no standard international index, which is why national income figures are used as a substitute. But the use of these figures to compare the standard of living between countries needs to be done carefully, because they are, at best, only a rough guide which can be misleading. The main problem here is that it is necessary to have a common unit of measurement if any sort of comparison is to be made at all. It has become the custom to use the dollar, and each country's currency is converted at its official exchange rate into a national income figure in dollars. Now, since the exchange rate is often set at an artificial level in relation to dollars, you are likely to end up with a figure that is useless for your purposes. `,
    ans: "",
  },
  {
    id: 25,
    ques: ` Naps aren't generally included in the litany of good-for-your-heart lifestyle choices recommended for lowering cardiovascular risk, but they may soon be. New research suggests a midday siesta may reduce a person's risk of death from heart disease, possibly by lowering stress levels. The findings must be confirmed, but Dimitrios Trichopoulos, MD, a study author, tells us that there is little downside to taking naps — and there could be big health benefits. "The siesta is a victim of progress. Most of us aren't in the position to take a daily nap," he says. "But our research suggests that the practice could help protect the heart, and we need further studies to find out if this really is the case." Trichopoulos says the research stemmed from the observation that heart disease death rates are lower in Mediterranean and Latin American countries where midday siestas are part of the culture. His own earlier research in a Greek population provided weak evidence in favour of the nap hypothesis, but another, larger study, conducted in Costa Rica failed to show an association. The newly published Greek study by Trichopoulosl and colleagues from the Harvard School of Public Health in Boston, and Greece's University of Athens Medical School is the largest ever to examine the issue in a previously healthy population. A total of 23,681 residents of Greece with no history of heart disease, stroke, or cancer at enrollment were followed an average of 6.3 years. And the study revealed that people who took naps at least three times a week for average of at least 30 minutes were 37% less likely to die of heart disease than people who did not take regular naps. `,
    ans: "",
  },
  {
    id: 26,
    ques: ` We see stars all around, so why doesn't their combined light add up to make our night sky-- and surrounding space, for that matter--bright? German physicist Heinrich Wilhelm Olbers put the same puzzle this way in 1823: If the universe is infinite in size, and stars (or galaxies) are distributed throughout this infinite universe, then we are certain to eventually see a star in any direction we look. As a result, the night sky should be aglow. Why isn't it? In fact, the answer is far more profound than it appears. There have been many attempts at explaining this puzzle, dubbed Olbers' Paradox, over the years. One version implicated dust between stars and perhaps between galaxies. The idea was that the dust would block the light from faraway objects, making the sky dark. In reality, however, the light falling on the dust would eventually heat it up so that it would glow as brightly as the original sources of the light. Advertisement Another proposed answer for the paradox held that the tremendous red shift of distant galaxies--the lengthening of the wavelength of light they emit due to the expansion of the universe--would move light out of the visible range into the invisible infrared. But if this explanation were true, shorter, wavelength ultraviolet light would also be shifted into the visible range--which doesn't happen. `,
    ans: "",
  },
  {
    id: 27,
    ques: ` A day would come, Percy Shelley predicted in 1813, when "the monopolizing eater of animal flesh would no longer destroy his constitution by eating an acre at a meal". he explained: "the quantity of nutritious vegetable matter consumed in fattening the carcass of an ox would afford 10 times at the sustenance if gathered immediately is from at the bosom of at the earth. " two hundred years later, mainstream's agronomists and dietitians have caught up with at the na me give. a growing scientific consensus agrees that feeding cereals and beans to animals is an inefficient and extravagant way to produce human food, that there is a limited amount of grazing land, that the world will be hard-pressed to supply a predicted population of 9 billion people with a diet as rich in meat as the industrialized world currently enjoys, and that it's not a very healthy diet anyway. On top of this, livestock contribute significant towards global warming, generating 14.5% of all manmade greenhouse gas emissions, according to one much-quoted estimate from the United Nations. Now that the problem has been identified, the challenge is to persuade people in wealthy countries to eat less meat. That might seem a tall order, but governments have successfully persuaded people to quit smoking through a combination of public information, regulation and taxation. `,
    ans: "",
  },
  {
    id: 28,
    ques: ` The advantages and disadvantages of solar power compared to other forms of renewable energy have been greatly debated. While obviously superior to some forms of energy, solar power's high cost and efficiency dependent on geography have limited its appeal. However, a large number of advantages also merit further development and even possible adaptation for residences. Advantages of Solar Power Solar energy remains popular because it is both a renewable and clean source of energy. These advantages along with the hope that eventually nations can use solar power to decrease global warming ensure its popularity. Renewable Solar energy is a true renewable resource. All areas of the world have the ability to collect some amount of solar power and solar power is available for collection each day. Clean Solar energy is non-polluting. It does not create greenhouse gases, such as oil-based energy does, nor does it create waste that must be stored, such as nuclear energy. It is also far more quiet to create and harness, drastically reducing the noise pollution required to convert energy to a useful form. Residential size solar energy systems also have very little impact on the surrounding environment, in contrast with other renewable energy sources such as wind and hydroelectric power. Low Maintenance Solar panels have no moving parts and require very little maintenance beyond regular cleaning. Without moving parts to break and replace, after the initial costs of installing the panels, maintenance and repair costs are very reasonable. `,
    ans: "",
  },
  {
    id: 29,
    ques: ` Many studies have indicated that from birth, infants imitate the behaviours and facial expressions of the adults around them. However, a team of Australian, South African and British researchers have released a study this week that refutes this widespread belief. "Numerous studies from the 1980s and 90s indicated no imitation by newborns, while others claimed it was there," says Virginia Slaughter, a biologist at the University of Queensland and co-author of the study. "We wanted to clear up the confusion because the 'fact' that newborns imitate is widely cited, not just in the fields of psychology, neuroscience and paediatrics, but also in popular sources for parents." The international research team, led by Janine Oostenbroek, a psychologist at the University of York in the UK, exposed more than 100 infants to a broad range of gestures and recorded their responses at one, two, six and nine weeks of age. The gestures included social cues like adults poking their tongues out, frowning or grinning, as well as non-social cues such as pointing or opening a box. The findings showed no link between behaviours exhibited by babies in their first few months and the gestures they were exposed to. The babies were just as likely to exhibit gestures they had never seen before as repeat ones they had. For instance, babies stuck their tongues out just as frequently if they were being exposed to pointing or opening a box, rather than anything to do with mouths or tongues. `,
    ans: "",
  },
  {
    id: 30,
    ques: ` Most of the time when I embark on such an investigation, it quickly becomes clear that matters are much more complicated and ambiguous — several shades grayer — than I thought going in. Not this time. The deeper I delved into the confused and confusing thicket of nutritional science, sorting through the long-running fats versus carb wars, the fiber skirmishes and the raging dietary supplement debates, the simpler the picture gradually became. I learned that in fact science knows a lot less about nutrition than you would expect – that in fact nutrition science is, to put it charitably, a very young science. It’s still trying to figure out exactly what happens in your body when you sip a soda, or what is going on deep in the soul of a carrot to make it so good for you, or why in the world you have so many neurons – brain cells! – in your stomach, of all places. It’s a fascinating subject, and someday the field may produce definitive answers to the nutritional questions that concern us, but — as nutritionists themselves will tell you — they’re not there yet. Not even close. Nutrition science, which after all only got started less than two hundred years ago, is today approximately where surgery was in the year 1650 – very promising, and very interesting to watch, but are you ready to let them operate on you? I think I’ll wait awhile. `,
    ans: "",
  },
  {
    id: 31,
    ques: ` How do we measure efficiency? To economists - or to a certain type of economist - it is simply a question of profitability, even when it concerns what most people consider a social provision such as public transport. What is lost when railway lines and bus routes to small, out-of-the-way communities are cut in the name of efficiency? After all, if a line or a route is only used occasionally by a few people,it would be much cheaper to rip up the lines and let everyone use their cars. For many governments, the way to turn inefficient national services into profitable businesses has been to sell off these services - and their responsibilities - to private enterprises. Cost, in terms of profit and loss, is of course an important factor, but other factors need to be considered when dealing with the livelihoods of whole communities, however small. Among these are the social, environmental, human and cultural costs incurred by cutting off more remote communities from greater opportunities, including economic activities that benefit society as a whole. Taking away such links - the usual result of privatization - may well lead to economic benefits in the short term, but, as the last twenty to thirty years have shown, also leads to long-term social and cultural damage. Of course, no business with its eye on profits is going to "waste" money supporting underused services. Only large collective bodies such as national and local governments can do that. These services are, after all, a social provision, not businesses. `,
    ans: "",
  },
  {
    id: 32,
    ques: ` Disabled people were among the early adopters of personal computers. They were quick to appreciate that word processing programs and printers gave them freedom from dependence on others to read and write for them. Some of these disabled early adopters became very knowledgeable about what could be achieved and used their knowledge to become independent students at a high level. They also gained the confidence to ask that providers of education make adjustments so that disabled students could make better use of course software and the web, rather than just word processing. For some disability groups, information in electronic format (whether computer-based or webbased) can be more accessible than printed information. For example, people who have limited mobility or limited manual skills can find it difficult to obtain or hold printed material; visually impaired people can find it difficult or impossible to read print, but both these groups can be enabled to use a computer and, therefore, access the information electronically. Online communication can enable disabled students to communicate with their peers on an equal basis. For example, a deaf student or a student with Asperger’s syndrome may find it difficult to interact in a face-to-face tutorial, but may have less difficulty interacting when using a text conferencing system in which everyone types and reads text. In addition, people’s disabilities are not necessarily visible in online communication systems; so disabled people do nit have to declare their disability and are not perceived as being different. `,
    ans: "",
  },
  {
    id: 33,
    ques: ` Twin studies have been very useful in giving us information about whether our genes or our environment makes us who we are. A surprising result is the way that genes influence our work. At a basic level, our genes affect how we look and so they influence whether we can become a basketball player or a supermodel, for example. However, there is evidence that genes influence our job choice in much greater ways. Research shows that identical twins choose more similar jobs than non-identical twins. In fact, identical twins who have grown up apart choose more similar jobs than non-identical twins who have grown up together. Studies also show that identical twins suggests that our genes affect both the satisfaction that comes from doing a job and satisfaction that comes from working conditions such as a person's pay or their manager. So what does this mean? It means that from birth, you are more likely to prefer one occupation to another and find certain jobs more satisfying than others. However, genes are not the only factor. Other things in your life, such as family background and education, will also be influential in your career choices. `,
    ans: "",
  },
  {
    id: 34,
    ques: ` With a good system of crop rotation, and especially with the addition of any sort of fertilizer you may be able to come up with, it’s possible to grow crops on a plot of land for upwards of 2 – 3 years at a time with good results. Ultimately, though, you must let the land rest if you hope to continue farming there in the long-run. Allowing a plot of land to rest for a period of time is known as letting the field go fallow, and there are several reasons for this. Allowing a field or plot to lie fallow means that you don’t grow anything new on it, don’t harvest anything and don’t graze any animals on the land for at least a year. Sometimes a field will lay fallow for two, three or even four years, but the traditional standard on many farms was to let a field lie fallow once every 2 – 3 years. This fallow period allows the land to replenish many of its nutrients. The root networks of various grasses or groundcovers (like clover) have a chance to expand and grow, which further strengthens the soil and protects it from erosion. During the fallow period, there are many beneficial flora and micro-fauna, including cyanobacteria, which live in the soil. These microorganisms continue to be active at the root level, steadily improving the quality of the soil so that when you come back in a year or two, you can begin planting food or cash crops anew. `,
    ans: "",
  },
  {
    id: 35,
    ques: ` The worldwide population of wild giant pandas increased by 268 over the last decade according to a new survey conducted by the government of China. The increase in population brings the total number of wild giant pandas to 1,864. The population increase represents 16.8% rise compared to the last panda survey in 2003. Wild giant pandas, a global symbol of wildlife conservation, are found only in China's Sichuan, Shaanxi and Gansu provinces. According to the report, formally known as the Fourth National Giant Panda Survey, the geographic range of pandas throughout China also increased. The total area inhabited by wild giant pandas in China now equals 2,577,000 hectares, an expansion of 11.8% since 2003. “These results are a testament to the conservation achievements of the Chinese government,” said Xiaohai Liu, executive director of programs, WWF-China. “A lot of good work is being done around wild giant panda conservation, and the government has done well to integrate these efforts and partner with conservation organizations including WWF.” The report, the fourth in a series of decadal (10 year) surveys conducted by the State Forestry Administration of China, began in 2011 with financial and technical support from WWF. Much of the success in increasing the panda population comes as a result of conservation policies implemented by the Chinese government, including the Natural Forest Protection Project and Grain for Green. `,
    ans: "",
  },
  {
    id: 36,
    ques: ` When Tim Berners-Lee invented the World Wide Web, he surely didn't anticipate that children would end up becoming some of its main users. Most start using the internet at the average age of three – and as recent research shows, children now spend more time playing and socializing online than watching television programs. Given this change in habits, it is not surprising that a recent House of Lords report has raised online safety and behavior as an important issue. The report said that for children, learning to survive in a world dominated by the internet should be as important as reading and writing. The House of Lords Communications Committee also warned that children should not be leaving school without "a well-rounded understanding of the digital world". It also suggested that the government should think about implementing new legal requirements and a code of conduct companies would have to adhere to, which would help to bring the internet up to "child-friendly standards". Of course, trying to rectify this lack of Child-centered design is not an easy task, but one that requires the cooperation and goodwill of many sectors. It will need to develop consultation with technology, education, legal and policy experts. And it would also be a good idea to make children and Young people part of the process. `,
    ans: "",
  },
  {
    id: 37,
    ques: ` The origins of writing are largely unclear. Writing systems were created independently all over the world. The earliest we know of were developed in the Middle East around 5,000 years ago. But other scripts were invented in India, Egypt, China and Central America. It has been suggested that some of these systems may have influenced others, but this has not been proved. These forms of writing look completely different, follow different rules and are often read in completely different ways. But they all perform the same basic function. They are all a visual means of recording language. Knowledge of some early scripts invented in certain regions was picked up by peoples living in surrounding areas. They would then adopt and adapt them to their own needs and language. Chinese, for example, was adopted in Japan and Korea, though it had to be altered to apply to the languages spoken there. Methods of recording information have varied over time and place. Not all sophisticated societies have developed writing systems and not all methods of recording information require writing. The Inca empire of South America was at its height in the sixteenth century AD and held power over a huge area that stretched from modern Equador and Peru, to areas of Bolivia and Chile. It was a complex civilisation, but did not develop a writing system. `,
    ans: "",
  },
  {
    id: 38,
    ques: ` Fish are being killed, and prevented from reaching maturity, by the litter of plastic particles finding their way into the world’s oceans, new research has proved. Some young fish have been found to prefer tiny particles of plastic to their natural food sources, effectively starving them before they can reproduce. The growing problem of microplastics – tiny particles of polymer-type materials from modern industry – has been thought for several years to be a peril for fish, but the study published on Thursday is the first to prove the damage in trials. Microplastics are near-indestructible in natural environments. They enter the oceans through litter, when waste such as plastic bags, packaging and other convenience materials are discarded. Vast amounts of these end up in the sea, through inadequate waste disposal systems and sewage outfall. Another growing source is microbeads, tiny particles of hard plastics that are used in cosmetics, for instance as an abrasive in modern skin cleaners. These easily enter waterways as they are washed off as they are used, flushed down drains and forgotten, but can last for decades in our oceans. The impact of these materials has been hard to measure, despite being a growing source of concern. Small particles of plastics have been found in seabirds, fish and whales, which swallow the materials but cannot digest them, leading to a build up in their digestive tracts. For the first time, scientists have demonstrated that fish exposed to such materials during their development show stunted growth and increased mortality rates, as well as changed behavior that could endanger their survival. `,
    ans: "",
  },
  {
    id: 39,
    ques: ` 130 Dendrochronology or tree ring dating is the scientific method of dating based on the analysis of patterns of tree rings, also known as growth rings. Dendrochronology can date the time at which tree rings were formed, in many types of wood, to the exact calendar year. This has three main areas of application: paleoecology, where it is used to determine certain aspects of past ecologists (most prominently climate) archaeology and the history of art and architecture, where it is used to date old panel paintings on wood, buildings etc; and radiocarbon dating, where it is used to calibrate radiocarbon ages. In some areas of the world, it is possible to date wood back a few thousand years, or even many thousands. As of 2013, fully anchored chronologies in the northern hemisphere extend back 13,900 years. Dendrochronology is more visible in temperate zones, where the seasons differ more markedly. The inner portion of a growth ring is formed early in the growing season, when growth is comparatively rapid (hence the wood is less dense) and is known as "early wood" (or "spring wood", or "late-spring wood"); the outer portion is the "late wood' (and has sometimes been termed 'summer wood", often being produced in the summer, though sometimes in the autumn) and is denser. Many trees in temperate zones make one growth ring each year, with the newest adjacent to the bark. Hence, for the entire period of a tree's life, a year-by-year record or ring pattern is formed that reflects the age of the tree and the climatic conditions in which the tree grew. Adequate moisture and a long growing season result in a wide ring, while a drought year may result in a very narrow one.`,
    ans: "",
  },
  {
    id: 40,
    ques: ` In a study conducted in Tubingen, Germany, chess experts and novices were shown geometric objects and chess positions and were later asked to identify each one of them. Their reaction times and brain activity closely monitored with the use of functional MRI scans. On the first part, which was recognizing the geometric objects, results reveal that the subjects’ performance didn’t show any dissimilarities, which implied that the experts’ visualization skills are no better than the amateurs’. However, during the identification of the chess position, the experts were seen to have performance significantly faster and better. As the researchers geared toward an element of a study previously conducted on pattern and object recognition by the chess experts, they had anticipated to notice areas of the left hemisphere of the experts’ brains (involved in object recognition) to be more reactive when they performed the tasks. However, the reaction times of the subjects were virtually identical. The very thing that sets the experts apart from the amateurs is that the former’s right brain hemispheres (involved in pattern recognition) were to seen to have also lit up during the activity. Therefore, both sides of the experts’ brains were active, processing information in two places simultaneously. The researchers added that when they showed the chess diagrams to the subjects, they observed that the amateur relied on looking at the pieces intently to be able to recognize them, whereas the experts merely relied on their peripheral vision and looked across the boards. `,
    ans: "",
  },
  {
    id: 41,
    ques: ` Their trade networks made the Phoenicians rich but also enabled cultural exchange and transfer between east and west in an unprecedented way: the most significant was the spread of the alphabetic script which was adopted all over the Mediterranean. The Phoenician alphabet is a writing system consisting of only 22 signs representing exactly one sound (phoneme) each. The term ""alphabet"" derives from the names of the first two signs in the sequence, aleph (""cattle"") and beit(""house""): these names also reflect the letters shapes, each derived from the picture of an object whose name starts with the relevant sound. The alphabetic script is simple enough to learn quickly, without the years of dedicated training required to master writing systems such as cuneiform or Egyptian hieroglyphs. Specialized schooling was unnecessary, and literacy was therefore disengaged from the institutional context of palaces and temples where the traditional scripts continued to be used. The alphabet suited the needs of long-distance merchants who needed to be able to record their business affairs on the go and who, for reasons of confidentiality and money, often preferred to write themselves rather than employ a specialist scribe. As the script could easily be used to record any language, it was, in the course of the first millennium bc, adapted for Aramaic, Hebrew, Greek, Phrygian, Lydian, Etruscan and Latin, to name but a few. `,
    ans: "",
  },
  {
    id: 42,
    ques: ` Ecology is the study of interactions of organisms among themselves and with their environment. It seeks to understand patterns in nature (e.g., the spatial and temporal distribution of organisms) and the processes governing those patterns. Climatology is the study of the physical state of the atmosphere – its instantaneous state or weather, its seasonal-to-interannual variability, its long-term average condition or climate, and how climate changes over time. These two fields of scientific study are distinctly different. Ecology is a discipline within the biological sciences and has as its core the principle of natural selection. Climatology is a discipline within the geophysical sciences based on applied physics and fluid dynamics. Both, however, share a common history. The origin of these sciences is attributed to Aristotle and Theophrastus and their books Meteorological and Enquiry into Plants, respectively, but their modern beginnings trace back to natural history and plant geography. Seventeenth, eighteenth, and nineteenth century naturalists and geographers saw changes in vegetation as they explored new regions and laid the foundation for the development of ecology and climatology as they sought explanations for these geographic patterns. Alexander von Humboldt, in the early 1800s, observed that widely separated regions have structurally and functionally similar vegetation if their climates are similar. Alphonse de Candolle hypothesized that latitudinal zones of tropical, temperate, and arctic vegetation are caused by temperature and in 1874 proposed formal vegetation zones with associated temperature limits. `,
    ans: "",
  },
  {
    id: 43,
    ques: ` Some "moments" seem more important in hindsight than they were at the time. David Day, for example, looks at John Curtin's famous "Australia looks to America" statement of December 1941, a moment remembered as embodying a fundamental shift in Australia's strategic alliance away from Britain towards the US. As Day points out, the shift to the US as our primary ally was a long, drawn-out process which occurred over half a century. Curtin's statement is iconic - it represents and symbolizes the shift - but in and of itself it made almost no difference. Russell McGregor makes similar arguments with regard to the 1967 referendum, falsely hailed in our memories as a huge advance in Aboriginal rights. There are many other important events which our contributors examine - the campaign to save the Franklin River; the landings at Gallipoli, the discovery of gold in 1851, the disastrous Premiers' Plan designed to cope with the Great Depression, to name just a few. Taken together, our contributors show that narrative approaches to Australian history are not as simple as might be imagined. There is of course the issue of what should be included and what should not be - what, after all, makes a moment or an event sufficiently important to be included in an official narrative? Just as importantly, the moments and events that are included in narrative histories are open to multiple interpretations. We hope this collection will provide an important reminder to those wanting to impose a universal history curriculum for our schoolchildren, and indeed a lesson to all Australians wishing to understand their nation's past; History is never simple or straightforward, and it always resists attempts to make it so. `,
    ans: "",
  },
  {
    id: 44,
    ques: ` The 1920's movie goers experience was largely dominated by silent movies but saw the introduction of synchronized sound. In the 1920's movie stars were really stars - with huge salaries, the fashions and activities of the Hollywood greats echoed around the world and 100,000 people would gather in cities all over the world, including such diverse cities as London and Moscow, to greet Mary Pickford and Douglas Fairbanks when they toured of Europe. Early silent movies were often accompanied by live piano or organ music and provided enormous entertainment value to audiences captivated by the experience of watching moving pictures on the silver screen. Although there had been previous attempts to introduce sound, it wasn’t until 1923 that a synchronized sound track was photographically recorded and printed on to the side of the strip of motion picture film and made it on to a commercially distributed movie. It would still be seven long years before talking pictures gained total supremacy and finally replaced the silent film era. The first movie theatres were called Nickelodeons, and were very basic compared the luxurious picture palaces that followed but what an aura of excitement, of laughter, fun and tears surrounded them! Before the introduction of movie soundtracks, movies were often accompanied by scripted music from a piano. `,
    ans: "",
  },
  {
    id: 45,
    ques: ` The world is shrinking rapidly with the advent of faster communication, transportation, and financial flows. Products developed in one country—Gucci purses, Sony electronics, McDonald’s hamburgers, Japanese sushi, German BMWs—have found enthusiastic acceptance in other countries. It would not be surprising to hear about a German businessman wearing an Italian suit meeting an English friend at a Japanese restaurant who later returns home to drink Russian vodka and watch Dancing with the Stars on TV. International trade has boomed over the past three decades. Since 1990, the number of multinational corporations in the world has grown from 30,000 to more than 63,000. Some of these multinationals are true giants. In fact, of the largest 150 “economies” in the world, only 81 are countries. The remaining 69 are multinational corporations. Walmart, the world’s largest company, has annual revenues greater than the GDP of all but the world’s 21 largest countries. Between 2000 and 2008, total world trade grew more than 7 percent per year, easily outstripping GDP output, which was about 3 percent. Despite a dip in world trade caused by the recent worldwide recession, the world trade of products and services last year was valued at more than $12 trillion, about 17 percent of GDP worldwide. Many U.S. companies have long been successful at international marketing: McDonald’s, Coca-Cola, Starbucks, GE, IBM, Colgate, Caterpillar, Boeing, and dozens of other American firms have made the world their market. In the United States, names such as Sony, Toyota, Nestlé, IKEA, Canon, and Nokia have become household words. Other products and services that appear to be American are, in fact, produced or owned by foreign companies. `,
    ans: "",
  },
  {
    id: 46,
    ques: ` Disabled people were among the early adopters of personal computers. They were quick to appreciate that word processing programs and printers gave them freedom from dependence on others to read and write for them. Some of these disabled early adopters became very knowledgeable about what could be achieved and used their knowledge to become independent students at a high level. They also gained the confidence to ask that providers of education make adjustments so that disabled students could make better use of course software and the web, rather than just word processing. For some disability groups, information in electronic format (whether computer-based or webbased) can be more accessible than printed information. For example, people who have limited mobility or limited manual skills can find it difficult to obtain or hold printed material; visually impaired people can find it difficult or impossible to read print, but both these groups can be enabled to use a computer and, therefore, access the information electronically. Online communication can enable disabled students to communicate with their peers on an equal basis. For example, a deaf student or a student with Asperger’s syndrome may find it difficult to interact in a face-to-face tutorial, but may have less difficulty interacting when using a text conferencing system in which everyone types and reads text. In addition, people’s disabilities are not necessarily visible in online communication systems; so disabled people do nit have to declare their disability and are not perceived as being different. `,
    ans: "",
  },
  {
    id: 47,
    ques: ` Promoting active lifestyles can help us address some of the important challenges facing the UKtoday. Increasing physical activity has the potential to improve the physical and mental healthof the nation, reduce all-cause mortality and improve life expectancy. It can also save moneyby significantly easing the burden of chronic disease on the health and social care services. Increasing cycling and walking will reduce transport costs, save money and help theenvironment. Fewer car journeys can reduce traffic, congestion and pollution, improving thehealth of communities. Other potential benefits linked to physical activity in children and young people include theacquisition of social skills through active play (leadership, teamwork and co-operation), betterconcentration in school and displacement of anti-social and criminal behavior. The importanceof physical activity for health was identified over 50 years ago. During the 1950s, comparisonsof bus drivers with more physically active bus conductors and office-based telephonists withmore physically active postmen demonstrated lower rates of coronary heart disease and smalleruniform sizes in the more physically active occupations. This research led the way for further investigation, and evidence now clearly shows theimportance of physical activity in preventing ill health. It is important for us to be activethroughout our lives. Physical activity is central to a baby’s normal growth and development. This continues through school, and into adulthood and older years. Being physically active canbring substantial benefits and there is consistent evidence of a dose–response relationship, i.e.the greater the volume of physical activity undertaken, the greater the health benefits that areobtained. `,
    ans: "",
  },
  {
    id: 48,
    ques: ` The evolution of the RAS (Royal Agricultural Society) fits into the wider Western trend of promoting nationalism, progress and technology through exhibitory venues, which first became popular in the 1850s. Various types of fairs, from local agricultural shows to Worlds Fairs, were used as instruments of hegemony to support imperialism, to promote burgeoning capitalist endeavors, and to shape class identities, social spaces and public spaces. Visual culture and the art of display became essential in defining aspects of national distinction. Colonial nations in particular, such as Canada and Australia, were attempting to develop distinct national identities to differentiate themselves from British imperial power. Agricultural fairs in North America originated at the beginning of the nineteenth century and were devoted to educating practicing framers in ways of improving their cultivation of livestock and crops through the use of various technologies. In 1822, the RAS was created on the premise that was a dire need in Australia for the development of improved farming skills to better support growing urban populations and export markets. Organizations based on agricultural improvement, which were popular in Britain, provided camaraderie as well as political and financial support for their members. Once transferred to the colonies, in this case Australia, they played an integral part in converting and organizing land for colonial purposes.`,
    ans: "",
  },
  {
    id: 49,
    ques: ` It was once believed that the brain was independent of metabolic processes occurring elsewhere in the body. In recent studies, however, we have discovered that the production and release in brain neurons of the neurotransmitter serotonin (neurotransmitters are compounds that neurons use to transmit signals to other cells) depend directly on the food that the body processes. Our first studies sought to determine whether the increase in serotonin observed in rats given a large injection of the amino acid tryptophan might also occur after rats ate meals that change tryptophan levels in the blood. We found that, immediately after the rats began to eat, parallel elevations occurred in blood tryptophan, brain tryptophan, and brain serotonin levels. These findings suggested that the production and release of serotonin in brain neurons were normally coupled with blood-tryptophan increases. In later studies we found that injecting insulin into a rat’s bloodstream also caused parallel elevations in blood and brain tryptophan levels and in serotonin levels. We then decided to see whether the secretion of the animal’s own insulin similarly affected serotonin production. We gave the rats a carbohydrate-containing meal that we knew would elicit insulin secretion. As we had hypothesized, the blood tryptophan level and the concentrations of tryptophan serotonin in the brain increased after the meal. `,
    ans: "",
  },
  {
    id: 50,
    ques: ` We know that Shakespeare took whole chunks of Plutarch word for word to use in his Roman plays — though, of course, in doing so he turned them into great poetry. Does this make Shakespeare a plagiarist? Was he a word thief? In its legal definition, plagiarism includes "both the theft or misrepresentation of intellectual property and the substantial textual copying of another's work". But it is also considered to be a factor of a particular culture or time — that is, in some cultures and in some periods the idea was undefined — which makes it harder to identify precisely. However, the main problem these days is plagiarism in academic writing, which is becoming increasingly common, due to the vast amount of material that has been published which can be accessed via the Internet. This easy access, coupled with the increasing pressure put on students, has led to a rapid rise in incidents of plagiarism. It comes down to who owns the intellectual property in question, and with the advent of the Internet this has become less clearly defined. `,
    ans: "",
  },
  {
    id: 51,
    ques: ` It’s important to realise that the brain doesn't see the world around it simply as though the scene was projected onto a cinema screen on the inside of your skull. Before a scene can be observed "in your head" it has to be broken down into a number of different components for processing, and these components then have to be recombined into the meaningful form that we call "an image". Amongst other things, the scene is broken down into its different colours — red, green and blue — in a way that's analogous to the manner in which a television image or magazine photograph is broken down into tiny dots of primary colours (which are too small to be noticed individually when we look at them, but which when seen collectively give the impression of a continuous full colour image). However, unlike and magazine images, the image that we see with our eyes is broken down not only into separate colour components but into other components too. It is, rather incredibly, deconstructed into component parts such as horizontal lines, vertical lines, circles and so on. Each of these component parts is sent to a separate area of the brain for processing, with the different components of the scene only merging again when they are unified into what you perceive as the image. `,
    ans: "",
  },
  {
    id: 52,
    ques: ` Getting to know fellow academics, especially more senior ones, can be very daunting. Lecturers and researchers are used to spending a lot of time in isolation working independently. The thought of going public and ‘selling yourself' does not seem enticing. However, it is easier than you think to begin to develop your own career-enhancing networks. Your PhD supervisor and examiners or if you are already in post, your mentor, are a great place to start. They will have been chosen to guide you because they are more experienced and in most cases they will work close to your field of interest. Ask their advice for ways of building up your own network of contacts. Also it is easier to approach someone unknown to you if you can mention the name of a mutual acquaintance. If you are a postgraduate who is serious about a career in academia, or a more senior scholar wanting to develop one, you will surely be attending conferences on a fairly regular basis. There is no right or wrong number of these, some scholars stick to one or two a year, others seem to attend one a month! Conferences are the main way that academics network with each other, so do not miss out on these opportunities. If you are presenting a paper it gives others a chance to see what you are working on, and the informal sections of the programmed (such as food and drink breaks) encourage mingling and further discussion `,
    ans: "",
  },
  {
    id: 53,
    ques: ` Current research into the nature of the relationship between participation in physical activity/sport and educational performance has produced mixed, inconsistent and often non-comparable results. For example, some cross-sectional studies illustrate a positive correlation between participation in sport and physical activity and academic success (e.g. maths, reading, acuity, reaction times). However, critics point to a general failure to solve the issue of direction of cause — whether intelligence leads to success in sport, whether involvement in sport enhances academic performance, or whether a third factor (e.g. personality traits) explains both. Longitudinal studies also generally support the suggestion that academic performance is enhanced, or at least maintained, by increased habitual physical activity. Yet such studies are criticized for not being definitive because some do not use randomised allocation of pupils to experimental and control groups (to control for pre-existing differences), others tend to use (subjective) teacher-assigned grades to assess academic achievement, rather than standardised and comparable tests; and some programmes include parallel interventions, making it difficult to isolate specific effects. More generically, one key piece of research illustrates that both acute exercise and chronic training programmes have small, but beneficial, positive impacts on cognitive performance. However, this study concludes that as experimental rigour decreased, effect size increased. Further, generalisation is limited because effect size is influenced by the nature and type of exercise, the type of participants, the nature of the cognitive tests and the methodological quality of the study. `,
    ans: "",
  },
  {
    id: 54,
    ques: ` Is the purpose of history to promote a strong national identity and support national myths? Certainly,it has been used in this way for centuries, and this is often reflected in the history curriculum. We can all remember history at school as being a matter of learning lots of facts and dates, and long lists of kings and queens - a grand narrative of how we got from a· not so civilized past to the great nation we are today. Putting aside the fact that national identity is a complex and divisive question - especially in countries like the UK, which is comprised of several nationalities - this approach to history emphasizes a broad understanding, rather than a detailed understanding. Yet history is, or should be, a critical, skeptical discipline: some historians see their work as disproving myths, demolishing orthodoxies. and exposing politically-motivated narratives which claim to be objective. What students need to develop are more critical and analytical skills; in other words, to think for themselves. They can do this by studying certain historical problems in depth. This involves being critical of the narratives presented by historians and skeptical of the myths preserved in the national memory. `,
    ans: "",
  },
  {
    id: 55,
    ques: ` An international team of scientists, including a physiologist from The University of Manchester, will head to the largest island in the world later this month to investigate the Greenland shark – believed to be the longest-lived vertebrate animal. Dr Holly Shiels, who is also a trustee of the Physiological Society, will be the only UK-based scientist on the expedition aboard the research vessel Sanna commissioned by the Greenland government. The purpose of the mission is to understand more about the Greenland shark, a top predator in the Arctic, which lives for more than 272 years - possibly more than 400. This extreme age was only revealed by scientists from Copenhagen last year and published in the journal Science. Little else is known about how the shark survives in the deep seas around the Arctic Circle. It is both a hunter and a scavenger and has been seen to feed on seals and been found with the remains of polar bears and whales in its stomach. It is also one of the largest species of shark – growing to about five-and-a-half metres, just a bit smaller than the great white. However, more information is required to ensure the species is adequately protected, as Dr Shiels explained: "Greenland sharks are classified as data deficient," she said. "This means that we don't know enough to put measures in place to protect them from over-fishing, pollution or climate change. This expedition has a broad range of expertise which means that we'll be able to take full advantage of any sharks that we discover." `,
    ans: "",
  },
  {
    id: 56,
    ques: ` Humans have been cultivating chilies as food for 6,000 years, but we are still learning new things about the science behind their heat and how it reacts with our body. In the late 1900's, scientists identified the pain nerves that detect capsaicin: the chemical in chillies responsible for most of the burning sensation in our mouth. But it's only during the last few years that scientists have also learnt why chilies evolved to be spicy in the first place, and they have managed to cultivate new varieties that are up to 300 times hotter than the common Jalapeno. The hottest part of a chilli is not the seeds, as many people think, but the white flesh that houses the seeds, known as the placenta. But why did chillies evolve to be hot in the first place? Most scientists believe capsaicin acts mainly as a deterrent against would-be mammal predators such as rodents. But recent research suggests this may not be the whole story. US scientists working in Bolivia have studied how hot and mild chillies differ in their susceptibility to a certain harmful fungus. It turns out that the hotter the chilli, the better its defences against the fungus, leading the researchers to propose that heat may have evolved to help chillies deal with harmful microbes, as well as hungry mammals. `,
    ans: "",
  },
  {
    id: 57,
    ques: ` The connection between international environmental law and policy and developments at a national level is becoming significantly closer. In the past two decades, many developed countries have greatly increased the number of statutes enacted to address environmental matters. This growth can be seen, in part, as a reflection of the number of international conventions being negotiated multilaterally and bilaterally. In the last five years, there also has been an increasing trend for developing countries and countries whose economies are in transition to introduce environmental legislation. This growth in the number of conventions and the consequential increase in environmental statutes on the same subjects is not surprising, given that conventions almost invariably place obligations on signatory countries to take steps, legal and otherwise, to implement their provisions. As a result of the increasing awareness of environmental problems at a national level, more national environmental law will be written, with similar approaches taken to similar problems. Greater similarity will also be encouraged by the fact that the law of developed countries is very often used as precedential material for the drafting of legislation in developing countries. Furthermore, homogenization of legislative approaches is encouraged by the publication of model legislation being developed by secretariats of international environmental conventions. For example, the Basel Convention Secretariat has published a comprehensive set of model national provisions on the movement of hazardous wastes. Finally, with more training programmes being conducted for lawyers and others by UNEP, UNDP and IUCN, common legislative approaches are often promoted. The connection between international environmental law and policy and developments at a national level is becoming significantly closer, and law of developed countries is very often used as precedential material for the drafting of legislation in developing countries, furthermore, homogenization of legislative approaches is encouraged by the publication of model legislation being developed by secretariats of international environmental conventions. `,
    ans: "",
  },
  {
    id: 58,
    ques: ` The shipping container is one of the mainstays of international trade. The globalized modern economy depends on the rapid and efficient movement of goods that containerization allows. In many ways, it was the advent of the container that allowed this globalized economy to develop. Invented during World War two as an efficient method of moving equipment to the front lines, there are now at any one time up to 15 million containers being used to transport goods on land and sea or waiting to be filled at factories And ports. They are vital in the supply chain and have allowed the added efficiency of "just in time" inventory management, where companies no longer keep large warehouses of stock or parts, but rely on the ability to quickly order what they want From their suppliers. It is estimated that since the 1980s the ratio of inventory to GDP in American business has fallen from 25% to 15%. Altogether total business inventory in the US is estimated at $1.5 trillion, without "just in time" management methods this might be as much as $2.5 trillion. This means that companies rely more and more on the prompt delivery of parts from their suppliers to the fulfill orders. this is as particularly to true of industries such as computer manufacture, which no longer the make all the parts of the products that bear their names, but instead out source, often field to the suppliers halfway around at the world. American computer manufacturers are, for example, increasingly dependent on Asian microchip manufacturers in the countries such as Taiwan and Thailand `,
    ans: "",
  },
  {
    id: 59,
    ques: ` In a study conducted in Tubingen, Germany, chess experts and novices were shown geometric objects and chess positions and were later asked to identify each one of them. Their reaction times and brain activity closely monitored with the use of functional MRI scans. On the first part, which was recognizing the geometric objects, results reveal that the subjects’ performance didn’t show any dissimilarities, which implied that the experts’ visualization skills are no better than the amateurs’. However, during the identification of the chess position, the experts were seen to have performance significantly faster and better. As the researchers geared toward an element of a study previously conducted on pattern and object recognition by the chess experts, they had anticipated to notice areas of the left hemisphere of the experts’ brains (involved in object recognition) to be more reactive when they performed the tasks. However, the reaction times of the subjects were virtually identical. The very thing that sets the experts apart from the amateurs is that the former’s right brain hemispheres (involved in pattern recognition) were to seen to have also lit up during the activity. Therefore, both sides of the experts’ brains were active, processing information in two places simultaneously. The researchers added that when they showed the chess diagrams to the subjects, they observed that the amateur relied on looking at the pieces intently to be able to recognize them, whereas the experts merely relied on their peripheral vision and looked across the boards. `,
    ans: "",
  },
  {
    id: 60,
    ques: ` Firstly, from the macroscopic view, the dominance of American English is not precipitated by the language itself, so the arising of English dominance in international communication is not solely the dominance of language itself. Just as the professor Jean Aitchison Oxford pointed out, the success of a language has much to do with the power of the people who use it but has little to do with internal features of the language. It is obvious in consideration to English. During the 18th century and 19th century, the influence of the British Empire began to spread around the world for the sake of industrial revolution, so English began to become popular. English was used not only in the British colonies but also in the diplomatic negotiations of non-English-speaking countries. However, no matter how powerful the adaptivity is and how large the area that the power of English covers, currently, the international status of English mainly springs from the status of America as a superpower after World War II. Besides, with the development of the economic globalization and new political structure, there is a great need of an international language. As result, American English became the first choice. `,
    ans: "",
  },
  {
    id: 61,
    ques: ` A farming technique practiced for centuries by villagers in West Africa, which converts nutrient-poor rainforest soil into fertile farmland, could be the answer to mitigating climate change and revolutionizing farming across Africa. A global study by researchers has for the first-time identified and analyzed rich fertile soils found in Liberia and Ghana. They discovered that the ancient West African method of adding charcoal and kitchen waste to highly weathered, nutrient poor tropical soils can transform the land into enduringly fertile, carbon-rich black soils which the researchers dub ‘African Dark Earths’. Similar soils created by Amazonian people in pre-Columbian eras have recently been discovered in South America — but the techniques people used to create these soils are unknown. Moreover, the activities which led to the creation of these anthropogenic soils were largely disrupted after the European conquest. Encouragingly researchers in the West Africa study were able to live within communities as they created their fertile soils. This enabled them to learn the techniques used by the women from the indigenous communities who disposed of ash, bones and other organic waste to create the African Dark Earths. `,
    ans: "",
  },
  {
    id: 62,
    ques: ` It was once assumed that all living things could be divided into two fundamental and exhaustive categories. Multicellular plants and animals, as well as many unicellular organisms, are eukaryotic—their large, complex cells have a well-formed nucleus and many organelles. On the other hand, the true bacteria are prokaryotic cell, which are simple and lack a nucleus. The distinction between eukaryotes and bacteria, initially defined in terms of subcellular structures visible with a microscope, was ultimately carried to the molecular level. Here prokaryotic and eukaryotic cells have many features in common. For instance, they translate genetic information into proteins according to the same type of genetic coding. But even where the molecular processes are the same, the details in the two forms are different and characteristic of the respective forms. For example, the amino acid sequences of various enzymes tend to be typically prokaryotic or eukaryotic. The differences between the groups and the similarities within each group made it seem certain to most biologists that the tree of life had only two stems. Moreover, arguments pointing out the extent of both structural and functional differences between eukaryotes and true bacteria convinced many biologists that the precursors of the eukaryotes must have diverged from the common ancestor before the bacteria arose. Although much of this picture has been sustained by more recent research, it seems fundamentally wrong in one respect. Among the bacteria, there are organisms that are significantly different both from the cells of eukaryotes and from the true bacteria, and it now appears that there are three stems in the tree of life. New techniques for determining the molecular sequence of the RNA of organisms have produced evolutionary information about the degree to which organisms are related, the time since they diverged from a common ancestor, and the reconstruction of ancestral versions of genes. These techniques have strongly suggested that although the true bacteria indeed form a large coherent group, certain other bacteria, the archaebacteria, which are also prokaryotes and which resemble true bacteria, represent a distinct evolutionary branch that far antedates the common ancestor of all true bacteria. `,
    ans: "",
  },
  {
    id: 63,
    ques: ` English is the world's lingua franca, the language of science, technology, business, diplomacy and popular culture. That probably explains why it is the world's most widely spoken language. It probably also explains why native English speakers are so reluctant to learn a second language. It's not worth the effort. In 2008, the European Commission carried out a survey of the European Union's 25 member states. The two with the lowest rates of bilingualism — defined as being able to hold a conversation in more than one language — were the UK and Ireland. About two-thirds of people in these countries speak only English. If a similar story wherever English is spoken as the mother tongue. Only about 25 per cent of US citizens can converse in another language. In Australia, the rates are even lower. Compare that with continental Europe, where multilingualism is the rule rather than the exception. More than half of EU citizens are bilingual, and not just because they live in countries like Luxembourg with multiple official languages. Even in France, which has only one official language and is immensely proud of its linguistic heritage, most people speak a second language. Again, that is largely down to the dominance of English. Across Europe, English is by far the most commonly learned language. High levels of bilingualism are not driven by a general desire to learn languages but a specific need to learn English. `,
    ans: "",
  },
  {
    id: 64,
    ques: ` Asda has become the first food retailer in the country to measure how much customers can save by cutting back on food waste, thanks to a Knowledge Transfer Partnership (KTP) with the University of Leeds. The idea behind the KTP was for the University, using Asda’s customer insight data, to apply its research to identify, investigate and implement ways of helping customers to reduce their food waste. This was one of the first times that a major retailer had tried to deliver large-scale sustainability changes, with the two-year project seen as a way for Asda to position themselves as true innovators in this area. The campaign focused on providing customers with advice on everything from food storage and labelling, to creative recipes for leftovers. Meanwhile, in-store events encouraged customers to make changes in their own homes. In fact, two million customers have said they will make changes to how they deal with food waste in their own homes, leading to an average saving of 57 pounds per customer, as well as a reduction in waste. A key aspect of a KTP is that an associate is employed by the University to work in the firm and help deliver the desired outcomes of the KTP. As a part of the collaboration with Asda, Laura Babbs was given the task of driving forward the sustainability changes in the retailer. As a result of the success of her work, Laura eventually became a permanent member of the team at Asda. `,
    ans: "",
  },
  {
    id: 65,
    ques: ` In recent months, drought and overgrazing in northern Kenya have sent thousands of herders and their livestock into national parks and other protected areas, intensifying tensions over land and grazing. Violence has taken the lives of several rangers, and a surge in wildlife killings is devastating populations of one of East Africa's most majestic beasts: giraffes. "This affects all wildlife, but giraffes may be particularly hard hit," says Fred Bercovitch, a zoologist at Kyoto University in Japan and director of Save the Giraffes, a nonprofit in San Antonio, Texas. For hunters, "giraffes are an easy target," he notes. And as scientists have recognized only recently, giraffes have multiple species, and several populations are already in serious decline. In the past 30 years, populations of two East African varieties, the Nubian and reticulated giraffes, have plunged by 97% and 78%, respectively, and the International Union for the Conservation of Nature may soon declare them critically endangered, says Doherty, who is involved in the assessment and leads the Reticulated Giraffe Project, a joint initiative with the Kenya Wildlife Service. In response to the threat, he and other scientists are stepping up research on the animals' birth and survival rates, movements, and interactions with resources and landscapes, hoping to pinpoint risks and focus conservation efforts `,
    ans: "",
  },
  {
    id: 66,
    ques: ` A plunging oil price has dragged UK inflation to zero over recent months. But analysts say the fall in retail prices cannot solely be attributed to oil. Discount retailers continue to steal market share from established industry giants, taking an increased chunk of both food and non-food markets. And, as retail analyst Nick Bubb notes, “the big supermarkets have had to respond to this by bringing down their own ‘rip off’ prices”. The result is a sector-wide fall in prices paid at the till. The growth of online retailers has also brought prices down, in part due to the ease with which customers can compare prices and purchase goods elsewhere if they find an item cheaper on a competitor’s site. Retailers are also reluctant to offer different prices in their physical and online stores, according to retail analyst Richard Hyman, which means shops are forced to cut prices on the high street. An ever-expanding range of shops is also to blame, according to Mr. Hyman. “Overcapacity is the biggest of the issues affecting prices,” he says. “In the last 10 years, online alone has added the equivalent of 110m square feet of trading space — that’s roughly equal to 65 additional Westfield London shopping malls. An increase in supply of retailers, with no increase in demand, has left the industry massively oversupplied." `,
    ans: "",
  },
  {
    id: 67,
    ques: ` During the time of the Aztecs, cocoa was mainly used as a beverage. Wines and drinks were made from white pulp around the seeds of the cocoa pod. The beans themselves were used to make hot or cold chocolate drinks. Both the Maya and the Aztec secular drinks used roasted cocoa beans, a foaming agent sugar, toasted corn and water. Vanilla and/or chilli were also used as an ingredient in the drinks. Cocoa beans were also used as a currency and as a tribute tax from peoples ruled by Aztecs. The oily layer floating in the chocolate drink cocoa butter was used to protect the skin against the sun. For the Aztecs cocoa had a religious significance. Cocoa was believed to be of divine origin: the cocoa tree was a bridge between earth and heaven. Human sacrifices to propitiate God or sun were first sanctified by giving him chocolate. Cocoa beans were given to priest’s assistants at children’s coming of age ceremonies. During marriage ceremonies, the couple drank a symbolic cup of chocolate and exchanged cocoa beans. Aztecs believed that drinking chocolate gave mortals some of Quetzalcoatl wisdom. – God of learning and of the wind. `,
    ans: "",
  },
  {
    id: 68,
    ques: ` By far the most popular and most consumed drink in the world is water, but it may come as no surprise that the second most popular beverage is tea.Although tea was originally grown only in certain parts of Asia – in countries such as China, Burma and India – it is now a key export product in more than 50 countries around the globe. Countries that grow tea, however, need to have the right tropical climate, which includes up to 200 centimeters of rainfall per year to encourage fast growth, and temperatures that range from ten to 35 degrees centigrade. They also need to have quite specific geographical features, such as high altitudes to promote the flavor and taste of the tea, and land that can offer plenty of shade in the form of other trees and vegetation to keep the plants cool and fresh. Together these conditions contribute to the production of the wide range of high-quality teas that are in such huge demand among the world’s consumers. There is green tea, jasmine tea, earl grey tea, pepper mint tea, tea to help you sleep, tea to promote healing and tea to relieve stress; but above all, tea is a social drink that seems to suit the palates and consumption habits of human beings in general. `,
    ans: "",
  },
  {
    id: 69,
    ques: ` Biomimicry (from bios, meaning life, and mimesis, meaning to imitate) is a new science that studies nature’s best ideas and then imitates these designs and processes to solve human problems. Studying a leaf to invent a better solar cell is an example. I think of it as ‘innovation inspired by nature.’ The core idea is that nature, imaginative by necessity, has already solved many of the problems we are grappling with. Animals, plants, and microbes are the consummate engineers. They have found what works, what is appropriate, and most important, what lasts here on Earth. This is the real news of biomimicry: After 3.8 billion years of research and development, failures are fossils, and what surrounds us is the secret to survival. Like the viceroy butterfly imitating the monarch, we humans are imitating the best and brightest organisms in our habitat. We are learning, for instance, how to harness energy like a leaf, grow food like a prairie, build ceramics like an abalone, self-medicate like a chimp, compute like a cell, and run a business like a hickory forest. The conscious emulation of life’s genius is a survival strategy for the human race, a path to a sustainable future. The more our world looks and functions like the natural world, the more likely we are to endure on this home that is ours, but not ours alone. `,
    ans: "",
  },
  {
    id: 70,
    ques: ` Manufacturing is no longer simply about making physical products. Changes in consumer demand, the nature of products, the economics of production, and the economics of the supply chain have led to a fundamental shift in the way companies do business. Customers demand personalization and customization as the line between consumer and creator continues to blur. Added sensors and connectivity turn "dumb" products into "smart" ones, while products increasingly become platforms—and even move into the realm of services. As technology continues to advance exponentially, barriers to entry, commercialization, and learning are eroding. New market entrants with access to new tools can operate at much smaller scale, enabling them to create offerings once the sole province of major incumbents. While large-scale production will always dominate some segments of the value chain, innovative manufacturing models—distributed small-scale local manufacturing, loosely coupled manufacturing ecosystems, and agile manufacturing—are arising to take advantage of these new opportunities. Meanwhile, the boundary separating product makers from product sellers is increasingly permeable. Manufacturers are feeling the pressure—and gaining the ability—to increase both speed to market and customer engagement. And numerous factors are leading manufacturers to build to order rather than building to stock. In this environment, intermediaries that create value by holding inventory are becoming less and less necessary. Together, these shifts have made it more difficult to create value in traditional ways. At the same time, as products become less objects of value in their own right and more the means for accessing information and experiences, creating and capturing value has moved from delivering physical objects to enabling that access. `,
    ans: "",
  },
  {
    id: 71,
    ques: ` Many people have problems with irony, both in their everyday lives and as it is used or deployed in literature. We learn early on at school about "dramatic irony", that is, we are told, when the audience of a play is aware of some situation or circumstance, or has information that one or more characters in the play do not. If you like, you are sharing a secret with the writer — you are in the know. Perhaps, as you go about your daily business, irony is not so clear-cut. Here's an example: your neighbour draws your attention to how lovely the dandelions and daisies growing in your lawn are. Now, to someone not familiar with the care and attention many English people give to their gardens, this might need a bit of explanation. Lawns are grass, and are cut and rolled regularly so that a professional golfer could practice his putting on it. Daisies and dandelions are weeds. For a moment — but just for a moment — you wonder how serious your neighbour is being. Does he really think the weeds are lovely or is he telling you — in a rather superior way — that you're a lousy gardener? Irony, however, usually needs an audience; and not only does it need some people to get the point, it also very much needs there to be people who don't. There is, it has to be said, a rather undemocratic air of superiority about it. Irony is slippery, sometimes difficult to get a firm hold on, and can easily backfire, like a joke that falls flat. Those who don't like irony — usually those who don't get the point — argue that, in a world that is already difficult enough to deal with, why should we want to complicate things further? Why throw everything you say into doubt? Besides, there's an unpleasant air of intellectual snobbery about it, and that sort of thing doesn't go down well any more. `,
    ans: "",
  },
  {
    id: 72,
    ques: ` A company in the USA is paying its employees to sleep more. Staff at the insurance company Aetna will get $300 a year added to their salary if they get at least seven hours of sleep a night. That works out to just over an extra dollar for each night the employee sleeps over seven hours. The idea behind this scheme is employee performance. Human resources officials say employees will work better if they have slept well. They add that a workforce that is more awake and alert will mean the company will perform better. Staff can either record their sleep automatically using a wrist monitor that connects to Aetna's computers, or manually record how long they have slept every night. There are a number of studies that warn that not sleeping enough can affect our ability to do our job. The American Academy of Sleep Medicine said that the average worker in the USA loses 11.3 working days of productivity a year because of not getting enough sleep. This costs companies about $2,280 for one worker. It estimates that the US economy loses $63.2 billion a year because workers do not sleep more than seven hours a night. A 2015 study in Europe by the Rand Corporation found that staff who slept less than seven hours per night were far less productive than workers who had eight or more hours of sleep. The staff at Aetna also receive extra cash if they do exercise. `,
    ans: "",
  },
  {
    id: 73,
    ques: ` The English have the reputation of being a nation of tea drinkers, but this wasn't always the case. By the end of the 17th century, the English were the biggest coffee drinkers in the Western world, and coffee houses became the places to be seen. As well as gossip, you could pick up talk of the latest intellectual developments in science, politics, and so on, in this age of scientific discovery and progress. At first coffee houses were very basic; a room with a bar at one end and a few plain tables and chairs. Customers paid a penny for a bowl — not a cup — of coffee. A polite young woman was usually in charge of the bar because it was thought her presence would ensure that the customers didn't use bad language or cause any trouble. An added attraction was that coffee houses provided free newspapers and journals. But people didn't go to the coffee houses just to drink coffee. They went to talk. They soon developed from simple cafes, where anyone with a penny could go for a drink and a chat, into clubs. People started to go to coffee houses where they would find other people who had the same jobs or who shared their interests and ideas, to talk and conduct business. The great popularity of coffee houses lasted about a hundred years. In the later 18th century, increased trade with other countries made such luxuries as coffee cheaper and more easily available to the ordinary person. As a result people started to drink it at home. Also at this time more tea was imported from abroad, and the century of the coffee house was replaced by the domestic tea-party as the typical English social occasion `,
    ans: "",
  },
  {
    id: 74,
    ques: ` In 1953, B.F. Skinner visited his daughter’s maths class. The Harvard psychologist found every pupil learning the same topic in the same way at the same speed. A few days later he built his first "teaching machine", which let children tackle questions at their own pace. By the mid-1960s similar gizmos were being flogged by door-to door salesmen. Within a few years, though, enthusiasm for them had fizzled out. Since then education technology (edtech) has repeated the cycle of hype and flop, even as computers have reshaped almost every other part of life. One reason is the conservatism of teachers and their unions. But another is that the brain-stretching potential of edtech has remained unproven. Today, however, Skinner’s heirs are forcing the sceptics to think again (see article). Backed by billionaire techies such as Mark Zuckerberg and Bill Gates, schools around the world are using new software to "personalize" learning. This could help hundreds of millions of children stuck in dismal classes—but only if edtech boosters can resist the temptation to revive harmful ideas about how children learn. To succeed, edtech must be at the service of teaching, not the other way around. The conventional model of schooling emerged in Prussia in the 18th century. Alternatives have so far failed to teach as many children as efficiently. Classrooms, hierarchical year-groups, standardized curriculums and fixed timetables are still the norm for most of the world’s nearly 1.5bn schoolchildren. `,
    ans: "",
  },
  {
    id: 75,
    ques: ` A democratic country should have the right to decide whether to vote or not. It is strange that after decades of crawling up the political backside of the US, Australians don't have that right. Being fined for not voting reminds me of the old saying "you can lead a horse to water but you cannot make him drink". The fine is not for failing to vote but for failing to have your name marked off a list! Forcing people to make a decision just means they'll make the easiest, quickest decision they can, not the best one. You need an informed electorate for compulsory voting to work. However, the reality is that nobody knows anything about the candidates and promotional material is not readily available. I'd rather 80% of people didn't vote than have them all just pick the first recognizable name on the ballot sheet. Then at least the government is elected by the 20% who care and make informed decisions. Otherwise it is largely pot chance who gets elected. Furthermore, compulsory voting doesn't ensure that the entire electorate is engaged in the democratic process. Those who don't want to vote can simply turn up and get their name marked off, without even putting pencil to paper. But you're seriously deluding yourself if you think that this is what all those who don't care about government do when they turn up to the polling booth. Voluntary voting at least ensures those who vote are the ones that care enough to do so. Perhaps somebody could enlighten me as to the reason why, to the best of my knowledge, Australia is the only 'democracy' that has compulsory voting. It is certainly not compulsory in the USA, England, Canada, New Zealand, Philippines or any other European or Asian democracy that I am aware of. Compulsory voting is, however, mandatory in most communist regimes `,
    ans: "",
  },
  {
    id: 76,
    ques: ` Almost 120 years ago, during the first Gilded Age, sociologist Thorstein Veblen coined the term "conspicuous consumption". He used it to refer to rich people flaunting their wealth through wasteful spending. Why buy a thousand-dollar suit when a hundred-dollar one serves the same function? The answer, Veblen said, was power. The rich asserted their dominance by showing how much money they could burn on things they didn't need. While radical at the time, Veblen's observation seems obvious now. In the intervening decades, conspicuous consumption has become deeply embedded in the texture of American capitalism. Our new Gilded Age is even more Veblenian than the last. Today's captains of industry publicize their social position with private islands and superyachts while the president of the United States covers nearly everything he owns in gold. But the acquisition of insanely expensive commodities isn't the only way that modern elites project power. More recently, another form of status display has emerged. In the new Gilded Age, identifying oneself as a member of the ruling class doesn't just require conspicuous consumption. It requires conspicuous production. If conspicuous consumption involves the worship of luxury, conspicuous production involves the worship of labor. It isn't about how much you spend. It's about how hard you work. Nowhere is the cult of conspicuous production more visible than among America's CEOs. `,
    ans: "",
  },
  {
    id: 77,
    ques: ` Ethics is a set of moral obligations that define right and wrong in our practices and decisions. Many professions have a formalized system of ethical practices that help guide professionals in the field. For example, doctors commonly take the Hippocratic oath, which, among other things, states that doctors "do no harm" to their patients. engineers follow an ethical guide that states that they "hold paramount the safety, health, and welfare of the public" within these professions, as well as within science, the rules become so ingrained that practitioners rarely have to think about adhering to the ethic - it's part of the way they practice. And a breach of ethics is considered very serious, punishable at least within the profession (by revocation of a license, for example) and sometimes by the law as well. Scientific ethics calls for honesty and integrity in all stages of scientific practice, from reporting results regardless to properly attributing collaborators. This system of ethics guides the practice, from data collection to publication and beyond. Of as in other professions, the scientific ethic is deeply integrated into the way scientists work, and they are aware that the reliability of their work and scientific knowledge in general the depends upon adhering to that ethic. Many of the ethical principles & relate, to at the productions of photos unbiased scientific knowledge, which is critical the when others the try to build upon or extend research, findings. At the open publication of the data, the peer review, replication, and collaboration required by at the scientific ethic all help to keep science moving forward by validating research findings and confirming or raising questions about results. `,
    ans: "",
  },
  {
    id: 78,
    ques: ` Malaria parasites leave a trail of destruction in an infected person’s body. The microscopic invaders massacre red blood cells, produce harmful chemicals, and sometimes damage the brain. A new mouse study suggests that the parasites can also weaken bones. If they do the same in people, they could stunt the growth of children infected with the disease. But the study also provides some good news, identifying a potential way to prevent the skeletal decline with a compound similar to vitamin D. “It’s important work,” says parasitologist Regina Joice Cordy of Emory University in Atlanta, who wasn’t connected to the study. “It’s taken us a step further,” she adds, in understanding the long-term effects of malaria infections. Malaria parasites, which are transmitted through the bite of an infected mosquito, cause the most destruction during the part of their life cycle when they dwell in red blood cells circulating through the body. There, they reproduce and feast on oxygen-carrying hemoglobin proteins, releasing noxious byproducts. The parasites eventually explode from the blood cells, killing them in droves. Although researchers have also detected the parasites in bone marrow, where blood-forming stem cells reside, no one has known until now whether they damage the skeleton. `,
    ans: "",
  },
  {
    id: 79,
    ques: ` It’s very easy to forget about what’s in the ground beneath our feet and why it’s so important to protect it. One tablespoon of soil contains more organisms than there are people on Earth; billions of bacteria, fungi and other microorganisms combine with minerals, water, air and organic matter to create a living system that supports plants and, in turn, all life. Healthy soil can store as much as 3,750 tons of water per hectare, reducing the risk of flooding, and the International Panel on Climate Change (IPCC) has said that 89% of all agricultural emissions could be mitigated if we improved the health of our soil. Good soil management also increases disease resistance in livestock and ultimately drives profits for farmers – yet soil and its impact on the health of our animals has, over recent decades, been one of the most neglected links in UK agriculture. Over the last 50 years’ agriculture has become increasingly dependent on chemical fertilizers, with applications today around 10 times higher than in the 1950s. Farmers often think the chemical fertilizer NPK (nitrogen, phosphorous and potassium) provides all the nutrition a plant requires, but it also has a detrimental effect on the long-term health of the land: research suggests there are fewer than 100 harvests left in many of the world’s soils. `,
    ans: "",
  },
  {
    id: 80,
    ques: ` Life expediencies have been rising by up to three months a year since 1840, and there is no sign of that flattening. Lynda Gratton and Andrew Scott draw on a 2009 study to show that if the trend continues, more than half the babies born in wealthier countries since 2000 may reach their 100th birthdays. With a few simple, devastating strokes, Gratton and Scott show that under the current system it is almost certain you wont be able to save enough to fund several decades of decent retirement. For example, if your life expectancy is 100, you want a pension that is 50percent of your final salary, and you save 10 percent of your earnings each year, they calculate that you wont be able to retire till your 80s. People with 100-year life expediencies must recognize they are in for the long haul, and make an early start arranging their lives accordingly.But how to go about this? Gratton and Scott advance the idea of a multistage life, with repeated changes of direction and attention. Material and intangible assets will need upkeep, renewal or replacement. Skills will need updating, augmenting or discarding, as will networks of friends and acquaintances. Earning will be interspersed with learning or self-reflection. As the authors warn, recreation will have to become re-creation. `,
    ans: "",
  },
];
